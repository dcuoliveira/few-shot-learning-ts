{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieloliveira/opt/anaconda3/envs/fsl-ts/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"bmh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_input, n_output) -> None:\n",
    "        super().__init__()\n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "\n",
    "        self.fc0 = nn.Sequential(\n",
    "                    nn.Linear(self.n_input, 256),\n",
    "                    nn.LeakyReLU(0.2)\n",
    "                    )\n",
    "        self.fc1 = nn.Sequential(\n",
    "                    nn.Linear(256, 512),\n",
    "                    nn.LeakyReLU(0.2)\n",
    "                    )\n",
    "        self.fc2 = nn.Sequential(\n",
    "                    nn.Linear(512, self.n_output),\n",
    "                    nn.Tanh()\n",
    "                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_input, n_output) -> None:\n",
    "        super().__init__()\n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "\n",
    "        self.fc0 = nn.Sequential(\n",
    "                    nn.Linear(self.n_input, 256),\n",
    "                    nn.LeakyReLU(0.2)\n",
    "                    )\n",
    "        self.fc1 = nn.Sequential(\n",
    "                    nn.Linear(256, 512),\n",
    "                    nn.LeakyReLU(0.2)\n",
    "                    )\n",
    "        self.fc2 = nn.Sequential(\n",
    "                    nn.Linear(512, self.n_output),\n",
    "                    nn.Sigmoid()\n",
    "                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Load data and filter rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from settings import INPUTS_PATH\n",
    "import torch.nn.functional as F\n",
    "\n",
    "data = pd.read_csv(os.path.join(INPUTS_PATH, \"adult.csv\"))\n",
    "data = data[data != \"?\"].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>216864</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3770</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>150601</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>3770</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "5   34   Private  216864       HS-grad              9       Divorced   \n",
       "6   38   Private  150601          10th              6      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "5      Other-service      Unmarried  White  Female             0   \n",
       "6       Adm-clerical      Unmarried  White    Male             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "1          4356              18  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  \n",
       "5          3770              45  United-States  <=50K  \n",
       "6          3770              40  United-States  <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.copy()\n",
    "num_cols = ['age', 'education.num', 'hours.per.week']\n",
    "cat_cols = []\n",
    "\n",
    "n_epoch = 10\n",
    "n_iter = 10\n",
    "batch_size_perc = 0.2\n",
    "\n",
    "learning_rate = 2e-4\n",
    "criterion = F.binary_cross_entropy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "num_cols_df = data[num_cols]\n",
    "cat_cols_df = data[cat_cols]\n",
    "\n",
    "# scale numerical columns\n",
    "num_scaler = MinMaxScaler()\n",
    "num_scaler.fit(data[num_cols])\n",
    "proc_num_cols_df = num_scaler.transform(data[num_cols])\n",
    "\n",
    "# scale categorical columns\n",
    "cat_scaler = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "cat_scaler.fit(data[cat_cols])\n",
    "proc_cat_cols_df = cat_scaler.transform(data[cat_cols])\n",
    "\n",
    "if (proc_num_cols_df.shape == 0) and (proc_cat_cols_df.shape == 0):\n",
    "    raise Exception(\"No data left in the preprocess step\")\n",
    "elif proc_num_cols_df.shape[1] == 0:\n",
    "    proc_data = torch.tensor(proc_cat_cols_df.copy()).float()\n",
    "elif proc_cat_cols_df.shape[1] == 0:\n",
    "    proc_data = torch.tensor(proc_num_cols_df.copy()).float()\n",
    "else:\n",
    "    proc_data = np.concatenate([proc_num_cols_df, proc_cat_cols_df], axis=1).float()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_random_data_batch(data, batch_size):\n",
    "    nrows = data.shape[0]\n",
    "\n",
    "    bathc_idx = np.random.randint(low=0, high=nrows, size=batch_size)\n",
    "    selected_data = data[bathc_idx, :]\n",
    "\n",
    "    return torch.tensor(selected_data).float()\n",
    "\n",
    "def train_discriminator(batch_data, d_optimizer):\n",
    "    ncols = batch_data.shape[1]\n",
    "    \n",
    "    # clean discriminato gradient\n",
    "    d_optimizer.zero_grad()\n",
    "\n",
    "    # run discriminator on real data\n",
    "    predictions_real = discriminator.forward(x=batch_data)\n",
    "\n",
    "    # generate fake data\n",
    "    noise = torch.normal(mean=0, std=1, size=(batch_size, ncols))\n",
    "    gen_data = generator.forward(x=noise)\n",
    "\n",
    "    # run discriminator on fake data\n",
    "    prediction_fake = discriminator.forward(x=gen_data)\n",
    "\n",
    "    # update discriminator loss\n",
    "    fake_loss = F.binary_cross_entropy(prediction_fake, torch.zeros((batch_size, 1)))\n",
    "    real_loss = F.binary_cross_entropy(predictions_real, torch.ones((batch_size, 1)))\n",
    "    d_loss = fake_loss + real_loss\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/gwwq15s92v97s_yvjxy3cqn40000gn/T/ipykernel_56819/733733988.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(selected_data).float()\n"
     ]
    }
   ],
   "source": [
    "# util dims\n",
    "nrows = proc_data.shape[0]\n",
    "ncols = proc_data.shape[1]\n",
    "batch_size = int(nrows * batch_size_perc)\n",
    "\n",
    "# instantiate generator and discriminator\n",
    "generator = Generator(n_input=proc_data.shape[1], n_output=proc_data.shape[1])\n",
    "discriminator = Discriminator(n_input=proc_data.shape[1], n_output=1)\n",
    "\n",
    "# define optimizers\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "## for epoch in range(n_epochs):\n",
    "##   for i in range(n_iter):\n",
    "\n",
    "epoch = 0\n",
    "i = 0\n",
    "\n",
    "batch_data = get_random_data_batch(data=proc_data, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Train discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean discriminato gradient\n",
    "d_optimizer.zero_grad()\n",
    "\n",
    "# run discriminator on real data\n",
    "predictions_real = discriminator.forward(x=batch_data)\n",
    "\n",
    "# generate fake data\n",
    "noise = torch.normal(mean=0, std=1, size=(batch_size, ncols))\n",
    "gen_data = generator.forward(x=noise)\n",
    "\n",
    "# run discriminator on fake data\n",
    "prediction_fake = discriminator.forward(x=gen_data)\n",
    "\n",
    "# update discriminator loss\n",
    "fake_loss = F.binary_cross_entropy(prediction_fake, torch.zeros((batch_size, 1)))\n",
    "real_loss = F.binary_cross_entropy(predictions_real, torch.ones((batch_size, 1)))\n",
    "d_loss = fake_loss + real_loss\n",
    "d_loss.backward()\n",
    "d_optimizer.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Train generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m g_loss\u001b[39m.\u001b[39;49mbackward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fsl-ts/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fsl-ts/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "g_loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m# try to fool discriminator\u001b[39;00m\n\u001b[1;32m      8\u001b[0m g_loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mbinary_cross_entropy(prediction_fake, torch\u001b[39m.\u001b[39mones((batch_size, \u001b[39m1\u001b[39m)))\n\u001b[0;32m----> 9\u001b[0m g_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     10\u001b[0m g_optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fsl-ts/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fsl-ts/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "# clean generator gradient\n",
    "g_optimizer.zero_grad()\n",
    "\n",
    "# run discriminator on fake data\n",
    "prediction_fake = discriminator.forward(x=gen_data)\n",
    "\n",
    "# try to fool discriminator\n",
    "g_loss = F.binary_cross_entropy(prediction_fake, torch.ones((batch_size, 1)))\n",
    "g_loss.backward()\n",
    "g_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsl-ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a96909169be20e1b2916a9e2d89a157776e2ba56287999af418b477753947edc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
